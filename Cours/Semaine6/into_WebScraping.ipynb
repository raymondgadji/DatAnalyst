{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5353009e",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "\n",
    "#### Web Scraping, Qu’est-ce que c’est ?\n",
    "nous pouvons le définir comme l’utilisation d’un programme pour obtenir des données du Web en extrayant du contenu sans API (Application Program Interface).\n",
    "\n",
    "De nombreux sites disposent d’API auxquelles vous pouvez vous connecter et que vous pouvez utiliser pour extraire des données. Comme l’API Twitter. C’est génial! Mais parfois, vous avez besoin de données provenant d’un site qui n’a pas d’API. \n",
    "\n",
    "#### Où est-il utilisé ?\n",
    "\n",
    "Le web scraping est utilisé dans divers domaines et industries pour collecter des données à partir de sites web. \n",
    "\n",
    "1. **Veille concurrentielle :** Les entreprises utilisent le web scraping pour surveiller les activités de leurs concurrents, analyser les prix, suivre les commentaires des clients et obtenir des informations stratégiques.\n",
    "\n",
    "2. **Marketing en ligne :** Les spécialistes du marketing utilisent le web scraping pour collecter des données sur les tendances du marché, les comportements des consommateurs, et pour générer des leads en extrayant des informations de contacts.\n",
    "\n",
    "3. **Recherche et analyse :** Les chercheurs et les analystes utilisent le web scraping pour collecter des données nécessaires à leurs études, que ce soit dans les domaines académiques, scientifiques, ou d'analyse de marché.\n",
    "\n",
    "4. **Suivi des prix :** Les détaillants en ligne utilisent le web scraping pour surveiller les prix de leurs produits ainsi que ceux de leurs concurrents afin d'ajuster leurs stratégies de tarification.\n",
    "\n",
    "5. **Recrutement :** Les professionnels des ressources humaines utilisent le web scraping pour collecter des informations sur les candidats potentiels à partir de différents sites, comme les réseaux sociaux professionnels.\n",
    "\n",
    "6. **Analyse de sentiments :** Les entreprises analysent les opinions et les commentaires des clients sur les réseaux sociaux et les sites d'avis en utilisant le web scraping pour évaluer la perception de leurs produits ou services.\n",
    "\n",
    "7. **Gestion de contenu :** Certains agrégateurs de contenu utilisent le web scraping pour collecter des articles, des actualités et d'autres informations à partir de différents sites afin de les regrouper sur une plateforme unique.\n",
    "\n",
    "8. **Finance :** Dans le secteur financier, le web scraping est utilisé pour surveiller les marchés, collecter des données financières, et analyser les tendances économiques.\n",
    "\n",
    "Il est important de noter que l'utilisation du web scraping doit respecter les lois et les règlements en vigueur, ainsi que les politiques d'utilisation des sites web ciblés. Des pratiques éthiques sont essentielles pour éviter tout problème légal ou éthique.\n",
    "\n",
    "https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01\n",
    "\n",
    "1. **Respect des Conditions d'Utilisation** : Chaque site web a ses propres conditions d'utilisation qui définissent les règles pour accéder à son contenu. Il est impératif de respecter ces conditions. Certains sites web interdisent explicitement le web scraping dans leurs conditions d'utilisation.\n",
    "\n",
    "2. **Robots.txt** : Les webmasters peuvent spécifier les parties de leur site qu'ils ne souhaitent pas voir crawlées par des robots d'indexation, y compris les web scrapers. Respecter le fichier robots.txt est une bonne pratique éthique.\n",
    "\n",
    "3. **Fréquence des Requêtes** : Évitez de surcharger un site web avec un grand nombre de requêtes en un court laps de temps, car cela peut entraîner une surcharge du serveur et perturber le fonctionnement normal du site.\n",
    "\n",
    "4. **Attribution et Respect des Droits d'Auteur** : Si vous utilisez les données extraites à des fins publiques ou commerciales, assurez-vous de respecter les droits d'auteur des sites web sources. Citez les sources lorsque cela est nécessaire.\n",
    "\n",
    "5. **Protection des Données Personnelles** : Soyez conscient des lois et réglementations sur la protection des données. Évitez de collecter des informations personnelles sensibles sans consentement explicite.\n",
    "\n",
    "6. **Objectifs Légitimes** : Utilisez le web scraping à des fins légitimes. Évitez d'utiliser ces techniques pour des activités illégales, trompeuses ou nuisibles.\n",
    "\n",
    "7. **Transparence** : Si vous collectez des données à partir d'un site web, soyez transparent sur votre intention et la manière dont vous utiliserez ces données.\n",
    "\n",
    "9. **Éviter la Détérioration** : Évitez de causer des dommages au site web source. Assurez-vous que votre activité de scraping n'affecte pas négativement la performance du site.\n",
    "\n",
    "10. **Respect de la Politique de Respects des Bots** : Certains sites web fournissent des directives spécifiques aux bots et aux scrapers dans leur fichier robots.txt ou dans leurs en-têtes HTTP. Respectez ces directives.\n",
    "\n",
    "**=> Considération Éthique** : En général, faites preuve de bon sens et de considération éthique dans votre utilisation du web scraping. Si vous vous posez des questions sur la légitimité d'une pratique, il est préférable de demander la permission au site web concerné!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1101e",
   "metadata": {},
   "source": [
    "Voici trois approches de web scraping qui sont parmi les plus populaires :\n",
    "\n",
    "**1-** Envoi d’une requête HTTP, généralement via Requests, à une page Web, puis analyse le code HTML (généralement à l’aide de BeautifulSoup) qui est renvoyé pour accéder aux informations souhaitées.\n",
    "\n",
    "ex : Problème de web scraping standard, référez-vous à l’étude de cas.\n",
    "\n",
    "**2-** Utilisation d’outils habituellement utilisés pour les tests automatisés de logiciels, principalement Selenium, pour accéder au contenu d’un site Web par programmation. \n",
    "\n",
    "Cas d’utilisation typique : sites Web qui utilisent Javascript ou qui ne sont pas directement accessibles via HTML.\n",
    "\n",
    "**3-** Scrapy, qui peut être considéré comme un framework de web scraping général, qui peut être utilisé pour construire des araignées et gratter des données à partir de divers sites Web en minimisant les répétitions. \n",
    "\n",
    "Cas d’utilisation : Scraping d’avis Amazon.\n",
    "\n",
    "Bien que vous puissiez également récupérer des données à l’aide de n’importe quel autre langage de programmation, Python est couramment utilisé en raison de sa syntaxe simple ainsi que de la grande variété de bibliothèques disponibles à des fins de grattage en Python.\n",
    "\n",
    "Note : Étant donné que la combinaison standard de Requests + BeautifulSoup est généralement la plus flexible et la plus facile à prendre en main, nous noterons que les outils ci-dessus ne s’excluent pas mutuellement ; vous pouvez, par exemple, obtenir du texte HTML avec Scrapy ou Selenium, puis l’analyser avec BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580c8dd",
   "metadata": {},
   "source": [
    "## HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964aa188",
   "metadata": {},
   "source": [
    "\n",
    "### Inspecter un élément d’une page web\n",
    "\n",
    "- Accéder à une page Web\n",
    "- clic droit\n",
    "- Sélectionner Inspecter l’élément\n",
    "\n",
    "NB: vous ne devriez pas voir de fenêtre contextuelle ou de cadre affichant le code HTML d’une page Web.\n",
    "\n",
    "Chaque travail de webscraping est unique, car presque tous les sites Web sont uniques. \n",
    "\n",
    "#### Composants de base d’un site Web\n",
    "\n",
    "#### HTML\n",
    "HTML est l’abréviation de 'Hypertext Markup Language' et tous les sites Web sur Internet l’utilisent pour afficher des informations. Même le système de bloc-notes Jupyter l’utilise pour afficher ces informations dans votre navigateur. \n",
    "\n",
    "Si vous faites un clic droit sur un site Web et sélectionnez « Afficher la source de la page », vous pouvez voir le code HTML brut d’une page Web. Il s’agit des informations que Python examinera pour récupérer des informations. \n",
    "\n",
    "Jetons un coup d’œil au code HTML d’une simple page web :\n",
    "\n",
    "    <!DOCTYPE html>  \n",
    "    <html>  \n",
    "        <head>\n",
    "            <title>Title on Browser Tab</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1> Website Header </h1>\n",
    "            <p> Some Paragraph </p>\n",
    "        <body>\n",
    "    </html>\n",
    "    \n",
    "\n",
    "\n",
    "Chaque <tag> indique un type de bloc spécifique sur la page Web :\n",
    "\n",
    "    1.<DOCTYPE html> Les documents HTML commenceront toujours par cette déclaration de type, indiquant au navigateur qu’il s’agit d’un fichier HTML.\n",
    "    2. Les blocs de composants du document HTML sont placés entre <html> et </html>.\n",
    "    3. Les métadonnées et les connexions de script (comme un lien vers un fichier CSS ou un fichier JS) sont souvent placées dans le <head> bloc.\n",
    "    4. Le <title> bloc de balise définit le titre de la page Web (c’est ce qui apparaît dans l’onglet d’un site Web que vous avez\n",
    "    5. Est entre <body> et les </body> balises sont les blocs qui seront visibles par le visiteur du site.\n",
    "    6. Les titres sont définis par les <h1> <h6> balises through, où le nombre représente la taille de l’en-tête.\n",
    "    7. Les paragraphes sont définis par la <p> balise, il s’agit essentiellement d’un texte normal sur le site Web.\n",
    "    8. <header>, <main>, <footer> indique la partie des éléments de la page à laquelle appartiennent\n",
    "    9. <a href=\"\"></a> pour les hyperliens, active un lien dans la page\n",
    "    10. <ul>, <ol> crée des listes\n",
    "    11. <li> Contient des éléments dans des listes\n",
    "    12. <br> Insère un saut de ligne unique\n",
    "    13. pour les <table> tableaux <tr> , pour les lignes de tableau et <td> pour les colonnes de tableau.\n",
    "\n",
    "\n",
    "**Certaines Balises sont à fermeture automatique :**\n",
    "la plupart des balises HTML nécessitent une balise d’ouverture et une balise de fermeture. Il y en a cependant quelques-uns qui ne le font pas :\n",
    "\n",
    "    1. <img src=\"\"> crée une image dans la page\n",
    "\n",
    "    2. <br> Crée une rupture dans le contenu\n",
    "\n",
    "    3. <input type=\"\"> crée un champ de saisie\n",
    "\n",
    "    4. <hr> Crée une ligne dans la page\n",
    "    \n",
    "**IDs, Classes**\n",
    "    \n",
    "Les ID et les classes sont très similaires. Ceux-ci sont utilisés pour cibler des éléments spécifiques.\n",
    "\n",
    "    1. `<h1 id=\"en-tête-profil\"></h1>`\n",
    "\n",
    "    2. `<h1 class=\"en-tête-sujet\"></h1>`\n",
    "\n",
    "Les identifiants ne doivent être utilisés qu’une seule fois sur une page. Les identifiants peuvent également être utilisés pour amener l’utilisateur à une partie spécifique de la page. votre-site/#profile-photo chargera la page à côté de la photo de profil.\n",
    "\n",
    "Les classes peuvent être utilisées plusieurs fois sur une page.\n",
    "\n",
    "Voir (https://www.w3schools.com/tags/ref_byfunc.asp)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c969e",
   "metadata": {},
   "source": [
    "#### CSS\n",
    "\n",
    "CSS est l’abréviation de Cascading Style Sheets, c’est ce qui donne du « style » à un site web, y compris les couleurs et les polices, et même quelques animations ! CSS utilise des balises telles que **id** ou **class** pour connecter un élément HTML à une fonctionnalité CSS, telle qu’une couleur particulière. **id** est un identifiant unique pour une balise HTML et doit être unique dans le document HTML, essentiellement une connexion à usage unique. **class** définit un style général qui peut ensuite être lié à plusieurs balises HTML. \n",
    "\n",
    "En gros, si vous voulez qu’une seule balise html soit rouge, vous utiliserez une balise id, si vous voulez que plusieurs balises/blocs HTML soient rouges, vous créerez une classe dans votre document CSS, puis vous la lierez au reste de ces blocs.\n",
    "\n",
    "\n",
    "#### Suite prise en main de HTML & CSS :\n",
    "\n",
    "[W3School](http://www.w3schools.com/html/)\n",
    "\n",
    "[Codecademy](http://www.codecademy.com/tracks/web)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ccb9e",
   "metadata": {},
   "source": [
    "## Le WebScraping en étapes:\n",
    "\n",
    "Pour les bibliothèques nécessaires pour les exemples ci-dessous, vous pouvez accéder à votre ligne de commande et les installer avec Conda install (si vous utilisez la distribution Anaconda) ou pip install pour les autres distributions Python.\n",
    "\n",
    "1.) **Requests** : Ce module est utilisé pour visiter une URL et obtenir le contenu d'une page web.La bibliothèque \"Requests\" en Python est un outil populaire utilisé pour simplifier les opérations liées aux requêtes HTTP. Elle offre une interface simple et élégante pour envoyer des requêtes HTTP, gérer les cookies, les en-têtes, les sessions, et gérer d'autres aspects liés aux communications web. \"Requests\" permet aux développeurs d'interagir facilement avec des API, de récupérer des données à partir de sites web, et d'effectuer diverses opérations liées aux protocoles HTTP. Grâce à sa simplicité d'utilisation et à ses fonctionnalités puissantes, \"Requests\" est largement utilisée dans le domaine du web scraping, de l'automatisation web, et de l'accès aux services web.\n",
    "\n",
    "Vous pouvez le télécharger avec pip install requests ou conda install requests (pour la distribution Anaconda de Python) dans votre invite de commande.\n",
    "\n",
    "2.) **BeautifulSoup** :une bibliothèque Python qui facilite l'extraction d'informations à partir de documents HTML et XML. Elle offre des méthodes souples pour parcourir et rechercher des éléments dans le code source HTML/XML, facilitant ainsi l'analyse et la manipulation de données web.. \n",
    "\n",
    "Vous pouvez le télécharger avec pip install beautifulsoup4 ou conda install beautifulsoup4 (pour la distribution Anaconda de Python) dans votre invite de commande.\n",
    "\n",
    "3.) **parser HTML** :Beautiful Soup prend en charge différents parseurs (analysateurs) pour analyser le code source HTML ou XML. Deux des parseurs populaires utilisés avec Beautiful Soup sont \"lxml\" et \"html.parser\"...\n",
    "\n",
    "* lxml : \"lxml\" est un parseur externe qui est construit sur les bibliothèques C libxml2 et libxslt. Il est rapide, efficace et capable de gérer des documents HTML et XML complexes. \"lxml\" est souvent recommandé pour sa rapidité, en particulier lors du traitement de grandes quantités de données. \n",
    "\n",
    "\n",
    "* html.parser : \"html.parser\" est un parseur natif inclus dans la bibliothèque standard de Python. Il est plus lent que \"lxml\" mais peut être suffisant pour des tâches moins gourmandes en ressources. Aucune installation supplémentaire n'est nécessaire, car il fait partie de la bibliothèque standard. \n",
    "\n",
    "\n",
    "* html5lib : Il s'agit d'un parseur externe qui implémente l'algorithme de l'HTML Living Standard. Il est précis et capable de gérer des documents HTML mal formés, mais il est généralement plus lent que les autres parseurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af93c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests,BeautifulSoup4\n",
    "#conda install requests,beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc89f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289a6c7",
   "metadata": {},
   "source": [
    "### 1- Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af3c23",
   "metadata": {},
   "source": [
    "\n",
    "* HTTP est un protocol qui va permettre au client (vous, par le biais de votre navigateur) de communiquer avec un serveur connecté au réseau (le serveur HTTP installé sur le serveur d'un site).\n",
    "\n",
    "\n",
    "* Les requêtes vont toujours par paires : la demande (du client) et la réponse (du serveur). Si ce n'est pas le cas, c'est qu'un problème est survenu à un endroit du réseau.\n",
    "\n",
    "\n",
    "On considère l'URL **www.example.com** qui représente un site Web spécialement conçu pour servir d’exemple. \n",
    "\n",
    "*  Récupérer une page\n",
    "\n",
    "Les requêtes nous permettront de charger une page web en python afin de pouvoir l’analyser et la manipuler. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e451c71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the requests library to grab the page\n",
    "# Note, this may fail if you have a firewall blocking Python/Jupyter \n",
    "# Note sometimes you need to run this twice if it fails the first time\n",
    "res = requests.get(\"http://www.example.com\")\n",
    "type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac79db9",
   "metadata": {},
   "source": [
    "Cet objet est un objet requests.models.Response et il contient en fait les informations du site web, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e1b847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116f323",
   "metadata": {},
   "source": [
    "### Beautifulsoup\n",
    "\n",
    "Pour analyser la page extraite, nous utiliserons **BeautifulSoup** . \n",
    "\n",
    "Techniquement, nous pourrions utiliser notre propre script personnalisé pour rechercher des éléments dans la chaîne de **res.text**, mais la bibliothèque BeautifulSoup a déjà beaucoup d’outils et de méthodes intégrés pour récupérer des informations à partir du HTML.\n",
    "\n",
    "* Préparer l'objet Soup:\n",
    "\n",
    "Tout d’abord, nous devons transformer le code du site Web en un objet Python. Nous avons déjà importé la bibliothèque Beautiful Soup, nous pouvons donc commencer à appeler certaines des méthodes de la bibliothèque. \n",
    "\n",
    "on récupère le contenu de res avec **res.text** ou **res.content**, cela transforme le texte en un objet Python nommé **soup**.\n",
    "\n",
    "Remarque importante : vous devez spécifier le parser spécifique que Beautiful Soup utilise pour analyser votre texte. C’est ce qui est fait dans le deuxième argument de la fonction BeautifulSoup. La valeur par défaut est l’analyseur Python intégré, que nous pouvons appeler à l’aide de **html.parser**\n",
    "\n",
    "Vous pouvez également utiliser **lxml** ou **html5lib**. Ceci est bien décrit dans la [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser).\n",
    "\n",
    "En utilisant la fonction Beautiful Soup **prettify()**, nous pouvons imprimer la page pour voir le code imprimé de manière lisible et lisible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using BeautifulSoup you can create a \"soup\" object that contains all the \"ingredients\" of the webpage.\n",
    "soup = bs4.BeautifulSoup(res.content,\"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfb9c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Example Domain\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <style type=\"text/css\">\n",
      "   body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <h1>\n",
      "    Example Domain\n",
      "   </h1>\n",
      "   <p>\n",
      "    This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "   </p>\n",
      "   <p>\n",
      "    <a href=\"https://www.iana.org/domains/example\">\n",
      "     More information...\n",
      "    </a>\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465549f3",
   "metadata": {},
   "source": [
    "* Navigation dans la structure de données\n",
    "\n",
    "Beautiful Soup nous permet de naviguer dans la structure des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5981ba30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Example Domain</title>\n"
     ]
    }
   ],
   "source": [
    "# Access the title element\n",
    "print(soup.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ea5e0d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Domain\n"
     ]
    }
   ],
   "source": [
    "# Access the content of the title element\n",
    "print(soup.title.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b74fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n"
     ]
    }
   ],
   "source": [
    "# Access data in the first 'p' tag\n",
    "print(soup.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8c7df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre de la page: Example Domain\n",
      "Texte de la page: \n",
      "\n",
      "Example Domain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example Domain\n",
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "More information...\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraire le titre de la page\n",
    "title = soup.title.text\n",
    "print('Titre de la page:', title)\n",
    "\n",
    "# Extraire tout le texte de la page\n",
    "text = soup.get_text()\n",
    "print('Texte de la page:', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dc270",
   "metadata": {},
   "source": [
    "### Rechercher des élements \n",
    "\n",
    "Beautiful Soup propose plusieurs méthodes pour effectuer des recherches dans un objet soup. Ces méthodes permettent d'extraire des informations spécifiques à partir du document HTML ou XML. \n",
    "\n",
    "Voici les méthodes de recherche les plus utilisées :\n",
    "\n",
    "\n",
    "[List of Tags](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)\n",
    "\n",
    "[BeautifulSoup 4 Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38055006",
   "metadata": {},
   "source": [
    "#### select() \n",
    "\n",
    "* select() Utilise des sélecteurs CSS pour trouver les éléments correspondants, elle retourne une liste d'elts.\n",
    "\n",
    "* select_one() : Cette méthode est similaire à select(), mais elle retourne uniquement le premier élément correspondant.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a1c60",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<thead >\n",
    "<tr>\n",
    "<th>\n",
    "<p>Syntax to pass to the .select() method</p>\n",
    "</th>\n",
    "<th>\n",
    "<p>Match Results</p>\n",
    "</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>All elements with the <code>&lt;div&gt;</code> tag</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('#some_id')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>The HTML element containing the <code>id</code> attribute of <code>some_id</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('.notice')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>All the HTML elements with the CSS <code>class</code> named <code>notice</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div span')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>Any elements named <code>&lt;span&gt;</code> that are within an element named <code>&lt;div&gt;</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div &gt; span')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>Any elements named <code class=\"literal2\">&lt;span&gt;</code> that are <span><em >directly</em></span> within an element named <code class=\"literal2\">&lt;div&gt;</code>, with no other element in between</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "886a82b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>Example Domain</title>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation de la méthode .select() pour trouver tous les éléments avec le tag 'example'\n",
    "elements_with_class = soup.select('title')\n",
    "elements_with_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754cbf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>Example Domain</title>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"head > title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0af835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation de la méthode .select_one() pour trouver le premier élément avec l'ID 'example'\n",
    "element_with_id = soup.select('p')\n",
    "element_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "652568ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "2\n",
      "<class 'bs4.element.Tag'>\n",
      "<p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n"
     ]
    }
   ],
   "source": [
    "elements_with_class = soup.select('p')\n",
    "print(type(elements_with_class))\n",
    "print(len(elements_with_class))\n",
    "print(type(elements_with_class[0]))\n",
    "print(elements_with_class[0])\n",
    "print(elements_with_class[0].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88269c5c",
   "metadata": {},
   "source": [
    "=> select retourne une liste contenant tous les éléments (ainsi que leurs balises). Vous pouvez utiliser l’indexation ou même les boucle pour récupérer les éléments de la liste. \n",
    "\n",
    "Comme cet objet est toujours une balise spécialisée, nous pouvons utiliser des appels de méthode pour récupérer uniquement le texte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82241d4",
   "metadata": {},
   "source": [
    "#### find()  \n",
    "\n",
    "Cette méthode retourne le premier élément qui correspond au critère spécifié.\n",
    "\n",
    "\n",
    "\n",
    "**find(tags, keyword_args, attrs={'attr', 'value'})** --> [REf](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a01feb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recherche du premier paragraphe dans le document\n",
    "paragraph = soup.find('p')\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d268135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"body\").find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee5e0150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Example Domain</title>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"head\").find(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a6185",
   "metadata": {},
   "source": [
    "#### find_all() \n",
    "\n",
    "Cette méthode retourne une liste de tous les éléments correspondant au critère spécifié.\n",
    "\n",
    "**find_all(tags, keyword_args, attrs={'attr', 'value'})** --> [Liste des balises](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all)\n",
    "\n",
    "La méthode find_all() analyse l’ensemble du document à la recherche de résultats, mais parfois vous ne voulez trouver qu’un seul résultat. Si vous savez qu’un document n’a qu’une seule <body> balise, c’est une perte de temps de numériser l’ensemble du document à la recherche d’autres balises. Plutôt que de passer limit=1 à chaque fois que vous appelez find_all, vous pouvez utiliser la méthode find().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad3be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recherche de tous les paragraphes dans le document\n",
    "paragraphs = soup.find_all('p')\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c827c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "More information...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# le contenu de la balise \"p\" en indiquant son attribut de class (on affine la recherche)\n",
    "# noter que cet un attribut \"class\"\n",
    "# on peut récupérer des éléments avec tout attributs définis dans une balise\n",
    "for p in soup.find_all('p'):\n",
    "    print (p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53bdaa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ce8fd",
   "metadata": {},
   "source": [
    "#### Autres fonctions utiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2aa3fc",
   "metadata": {},
   "source": [
    "* find_parent(), find_parents() : Ces méthodes permettent de trouver le parent ou les parents d'un élément spécifié.\n",
    "    \n",
    "* find_next_sibling(), find_previous_sibling() : Trouve le frère suivant ou précédent d'un élément.\n",
    "    \n",
    "* find_next(), find_previous() : Trouve le prochain ou le précédent élément qui correspond à un critère spécifié.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b62d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<h1>Example Domain</h1>\n",
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>\n",
       "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trouver le parent du premier paragraphe\n",
    "parent_of_paragraph = paragraph.find_parent()\n",
    "parent_of_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a588d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trouver le frère suivant du premier paragraphe\n",
    "next_sibling = paragraph.find_next_sibling()\n",
    "next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be41efcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trouver le prochain élément div,p ..\n",
    "next_div = paragraph.find_next('p')\n",
    "next_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3016781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6017f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "195f53dd",
   "metadata": {},
   "source": [
    "# Ressources utiles : \n",
    "\n",
    "- Prise en main de HTML et CSS , Valider les ressources suivantes:\n",
    "\n",
    "    * http://www.codecademy.com/tracks/web\n",
    "\n",
    "    * http://www.w3schools.com/html/\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "- Veille technique:Respect de l'Éthique et de la Légalité : \n",
    "\n",
    "Examiner les questions éthiques liées au web scraping, y compris le respect des droits d'auteur, la politique des sites web et la collecte responsable des données, comment fonctionne le fichier robots.txt.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099eb2ed",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.ionos.fr/digitalguide/sites-internet/developpement-web/quest-ce-que-le-web-scraping/\n",
    "\n",
    "https://datascientest.com/decouvrir-le-web-scraping-avec-beautiful-soup\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
